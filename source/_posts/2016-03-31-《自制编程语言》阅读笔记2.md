---
layout: post
title: '《自制编程语言》阅读笔记 - 第二章计算器'
date: 2016-03-31 23:27:12
categories: 读书笔记
tags: 编译原理
---


# 一般语言语法处理过程

|  步骤  | 处理过程 | 功能              |
| :--: | :--: | :-------------- |
|  1   | 词法分析 | 代码文本分割为token    |
|  2   | 语法分析 | token构建抽象语法树AST |
|  3   | 语义分析 | 检查语义是否正确        |
|  4   | 代码生成 | 最终生成代码          |

<!--more-->

# 做一个计算器练手

感觉计算器就是初学编程时的helloworld，所以要好好理解其中涉及的内部机理，而不是满足于做出来一个计算器，要说实用的话，系统自带的计算器漂亮的多得多。

## lex

lex是**生成词法分析器**的工具，给lex输入`.l`文件，输出词法分析器的c代码，注意这里生成的时词法分析器的代码，不过代码经过编译就是词法分析器，从功能的角度来讲，lex生成的时词法分析器。我们使用lex的增强版flex。

词法分析器的作用是读取代码，生成token。所以我们要告诉lex，token长什么样子，这样lex才能帮我们做一个词法分析器出来。

在lex中使用**正则表达式**定义记号，这样做是有好处的：比如我们在程序中去描述

> C语言变量名是字母或下划线开头，后面可以是字母数字的组合

这样的规定没有比正则表达式更好的方式了。

> 开工啦~ 时间下午3:30



先看代码mycalc.l，通过代码高效地学习lex

```c
%{
#include <stdio.h>
#include "y.tab.h"

int
yywrap(void)
{
    return 1;
}
%}
%%
"+"             return ADD;
"-"             return SUB;
"*"             return MUL;
"/"             return DIV;
"\n"            return CR;
([1-9][0-9]*)|0|([0-9]+\.[0-9]*) {
    double temp;
    sscanf(yytext, "%lf", &temp);
    yylval.double_value = temp;
    return DOUBLE_LITERAL;
}
[ \t] ;
. {
    fprintf(stderr, "lexical error.\n");
    exit(1);
}
%%

```

### 区块划分

像上面的lex代码可以分为2个部分，每个部分的功能不同。

> %{
>
> ……
>
> }%



像这样的代码块，是**定义区块**。被包裹起来的部分，lex会原样输出到词法分析器的代码中。先不去深究这些代码是做什么用的，我们知道这里包含了2个头文件，定义了一个**yywrap**函数。

> %%
>
> ……
>
> %%

像这样的代码块，是**规则区块**。用正则表达式去描述token长什么样子。那具体是怎么描述的呢？

从规则区块再往下，就是用户代码区块，用户代码区块可以编写任何C代码，本例中没有用到。

### 规则区块代码分析

以这句代码为例

```cpp
"+"             return ADD;
```

正则表达式是个常量字符'+'，后面接空格作为分割，再后面是匹配到这个正则表达式要执行的动作(action)，这里简单地返回ADD标记。

更复杂一点的例子是

```cpp
([1-9][0-9]*)|0|([0-9]+\.[0-9]*) {
    double temp;
    sscanf(yytext, "%lf", &temp);
    yylval.double_value = temp;
    return DOUBLE_LITERAL;
}
```



这里的正则表达式为

```
([1-9][0-9]*)|0|([0-9]+\.[0-9]*)
```



用来匹配一个浮点型的数值。后面的动作是C代码块。定义双精度浮点型变量temp；sscanf是把yytext当做浮点数读入变量temp。那yytext是什么呢？假如这里匹配的浮点数是3.14，那么在action语句yytext代表了这个当前被匹配到的字符串文本，这里的例子中就是“3.14”。yytext是一个全局的变量，所以这里看不到声明。再接着

```cpp
yylval.double_value = temp;
return DOUBLE_LITERAL;
```

temp被存放于yylval.double_value中。实际上，yylval也是全局变量，同时是一个联合体，意味着可以存放各种类型的token的值。注意这里所说的**token的值**，这句话耐人寻味。然后返回一个DOUBLE_LITERAL的类型。

#### token要素

完全描述一个token的几个要素，或者说一个token有哪些属性组成，只要规定好了这几个属性就能确定一个token。类似于给定x,y就能在坐标轴上确定一个点的意思。token有3部分组成，还是以 “3.14”的例子来进行说明，假定我们的词法分析器已经做好了，正在读取文本中得代码进行词法分析，此时匹配到了字符串"3.14"：

1. 记号的原始字符串。这里是字符串"3.14"的字符串形式
2. 记号的值。这里的值是指3.14的双精度浮点数
3. 记号的种类。3.14的种类就是一个实数。在lex中用宏/枚举DOUBLE_LITERAL表示。



```
[ \t] ;
```

这句是匹配空格、制表符，然后什么都不做，这样子就过滤掉了每一行的空白字符。

```
. {
    fprintf(stderr, "lexical error.\n");
    exit(1);
}
```

点号可以匹配任意字符。放在这里的意思是上面我所规定的token都没有匹配到却还有其他字符，说明不符合语法规范，所以报错。这句体现了程序的健壮性。

## yacc

yacc是生成语法分析器的工具。输入.y的文件，输出语法分析器的C语言代码。假定lex可以很好的分割出一个个token给我们了，yacc做的工作是把这一连串token放进语法规范中进行处理，看是否符合此种语言语法规范。为此，我们必须提供这一语法规范给yacc。对比我们使用正则表达式描述token给lex，这里使用BNF描述语法给yacc。

mycalc.y的代码

```cpp
%{
#include <stdio.h>
#include <stdlib.h>
#define YYDEBUG 1
%}
%union {
    int          int_value;
    double       double_value;
}
%token <double_value>      DOUBLE_LITERAL
%token ADD SUB MUL DIV CR
%type <double_value> expression term primary_expression
%%
line_list
    : line
    | line_list line
    ;
line
    : expression CR
    {
        printf(">>%lf\n", $1);
    }
expression
    : term
    | expression ADD term
    {
        $$ = $1 + $3;
    }
    | expression SUB term
    {
        $$ = $1 - $3;
    }
    ;
term
    : primary_expression
    | term MUL primary_expression 
    {
        $$ = $1 * $3;
    }
    | term DIV primary_expression
    {
        $$ = $1 / $3;
    }
    ;
primary_expression
    : DOUBLE_LITERAL
    ;                 
%%
int
yyerror(char const *str)
{
    extern char *yytext;
    fprintf(stderr, "parser error near %s\n", yytext);
    return 0;
}

int main(void)
{
    extern int yyparse(void);
    extern FILE *yyin;

    yyin = stdin;
    if (yyparse()) {
        fprintf(stderr, "Error ! Error ! Error !\n");
        exit(1);
    }
}
```

1~5行，和lex的定义区块一样，也是代码原样输出。

6~9行，声明lex中用到的保存token值的联合体。从编译出来的y.tab.h文件中有以下定义可以看出这点来。

```cpp
typedef union YYSTYPE
{
    int          int_value;
    double       double_value;
} YYSTYPE;

extern YYSTYPE yylval;
```



第11行，声明不需要保存值，只需要知道token本身的种类的token。例如加号。

第10行，声明token类型为DOUBLE_LITERAL。DOUBLE_LITERAL类型的token是有值的，这个值可以存在union结构的double_value字段中。这一点书上的意思我不是很明白，可能我地理解力不好，也可能书上没有讲太清楚。

第12行，声明了非终结符的类型。这里留有一个疑问：为什么`<double_value>`也算非终结符。后面的那些是非终结符很好理解，因为他们可以根据下面的规则继续推导，而`<double_value>`也算进去了，我现在是不好理解的。

第13行到第48行，是一些推导规则。语法规则简化为下面格式

```
A
    : B C
    | D
    ;
```

意味着A可以由BC或D组成。这有点像树状图，A是树的顶端，下来分2个分支，一个分支是D，另一个分支是BC.D是什么可以接着推导，最终到不可推导的非终结符。



### 实例分析

假定输入表达式，看看yacc怎么根据BNF规则去完成语法分析

```
1 + 2 * 3 
```



语法分析类似于小时候玩儿的俄罗斯方块，下面通过正统的说法，来重温俄罗斯方块的乐趣。解析器内部有个栈，每次读取一个token到栈中，可以想象一个一个不同的token就是不同形状的方块。还可以看到下一个即将进入栈的token是什么。

#### 第一步

一开始是1，lex会把1替换成token也就是DOUBLE_LITERAL。DOUBLE_LITERAL进入栈中，此时同时能看到下一个即将进入栈的token是加号。如下图

![](http://7xn4yz.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-03-31%20%E4%B8%8B%E5%8D%887.00.02.png)



那么此时进入栈中的DOUBLE_LITERAL会触发规则

```
primary_expression
    : DOUBLE_LITERAL
    ; 
```

那么DOUBLE_LITERAL被**归约**（归约是往消除方向的化简过程）为primary_expression。注意primary_expression译作一元表达式。



现在堆栈的状态是

![](http://7xn4yz.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-03-31%20%E4%B8%8B%E5%8D%887.07.38.png)



再根据规则

```
term
    : primary_expression
```

变为term，再根据规则

```
expression
    : term
```

变为expression



#### 第二步

token ADD进来，找不到归约的条件，所以此时的状态是这样的。

![](http://7xn4yz.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-03-31%20%E4%B8%8B%E5%8D%887.14.59.png)

#### 第三步

字符2的token—DOUBLE_LITERAL进来，和之前的1一样，会经过primary_expression被归约到term。



为什么是term而不是expression呢？1是被归约到了expression，因为在1进入堆栈时，堆栈里没有值，所以可以随便归约，而此时堆栈里有

```
expression +
```

那么在对2进行每一步归约时，应该考虑到2归约出来的新的值是否能和堆栈里有得表达式进行归约。

也就是说，字符2的token—DOUBLE_LITERAL进来，我们首先要去考虑堆栈里

 ```
expression + DOUBLE_LITERAL 
 ```

这种表达式是否有归约的规则。若没有，再继续归约新表达式DOUBLE_LITERAL。



好，照这样的思路，来到这里

```
 expression + term(2的token)
```



在这里找到一条规则



    expression
    	: expression ADD term



按规则说这里可以直接归约成expression。由于yacc可以提前读到下一个即将进来的token，所以这里会考虑到下面的规则

    term
    	: term MUL primary_expression

万一再下一个是primary_expression，那么就可以归约到term了。（这条规则的位置比上一条规则要靠下面，所以优先？）



#### 第4步



接下来进来3，被归约为primary_expression之后，按照上面的提示直接归约为term，那么现在的堆栈如图所示

![](http://7xn4yz.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-03-31%20%E4%B8%8B%E5%8D%8810.22.43.png)



再接着匹配规则

```
expression
    expression ADD term
```

整个堆栈上只剩expression了。那么语法分析就已经完成了。



和lex一样，yacc在匹配到规则时，也有一个action被触发。

```
term
    : primary_expression
    | term MUL primary_expression 
    {
        $$ = $1 * $3;
    }
```

类似于C语言的语句。这里$1,$3之类的表达式分别保存了term、primary_expression的值，有图会比较明显



![](http://7xn4yz.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202016-03-31%20%E4%B8%8B%E5%8D%8810.30.23.png)

在进行这句递归的时候，代表的意义。



假如进行下面的递归时，并不是什么都不做，而是自动补全一句

```
term
    : primary_expression
    {
  		$$ = $1;
	}
```

这样，进行归约时，primary_expression包含的数值也会被term继承。$$、$1的包含数值的类型分别与其对应的token或者非终结符的类型一致。

```
%token <double_value>      DOUBLE_LITERAL
%type <double_value> expression term primary_expression
```

token的数值的类型借union中double_value字段定义。